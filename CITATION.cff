@inproceedings{10.5555/3709347.3743777,
author = {Manupriya, Piyushi and Himanshu and Jagarlapudi, SakethaNath and Ghalme, Ganesh},
title = {Multi-agent Multi-armed Bandits with Minimum Reward Guarantee Fairness},
year = {2025},
isbn = {9798400714269},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {We investigate the problem of maximizing social welfare while ensuring fairness in a multi-agent multi-armed bandit (MA-MAB) setting. In this problem, a centralized decision-maker takes actions over time, generating random rewards for various agents. Our goal is to maximize the sum of expected cumulative rewards, a.k.a. social welfare, while ensuring that each agent receives an expected reward that is at least a constant fraction of the maximum possible expected reward. Our proposed algorithm,  RewardFairUCB, leverages the Upper Confidence Bound (UCB) technique to achieve sublinear regret bounds for both fairness and social welfare. The fairness regret measures the positive difference between the minimum reward guarantee and the expected reward of a given policy, whereas the social welfare regret measures the difference between the social welfare of the optimal fair policy and that of the given policy. We show that  RewardFairUCB algorithm achieves instance-independent social welfare regret guarantees of \~{O}(T1/2 ) and a fairness regret upper bound of \~{O}(T3/4 ). We also give the lower bound of Ω(√T) for both social welfare and fairness regret. We evaluate  RewardFairUCB's performance against various baseline and heuristic algorithms using simulated data and real world data, highlighting trade-offs between fairness and social welfare regrets.},
booktitle = {Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems},
pages = {1436–1444},
numpages = {9},
keywords = {fairness, multi-agent systems, multi-armed bandits, regret analysis},
location = {Detroit, MI, USA},
series = {AAMAS '25}
}
